p8105\_hw2\_ph2538
================
Pei Yang Hsieh
2018-09-28

``` r
library(tidyverse)
```

    ## -- Attaching packages --------------------------------------------------------------------- tidyverse 1.2.1 --

    ## v ggplot2 3.0.0     v purrr   0.2.5
    ## v tibble  1.4.2     v dplyr   0.7.6
    ## v tidyr   0.8.1     v stringr 1.3.1
    ## v readr   1.1.1     v forcats 0.3.0

    ## -- Conflicts ------------------------------------------------------------------------ tidyverse_conflicts() --
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(ggplot2)
library(readxl)
library(devtools)
```

The purpose of this file is to complete homework
2.

## Problem 1

### Loading and Cleaning Data

``` r
#Load and clean data: retain line, station, name, station latitude/longitude, routes served, entry, vending, entrance type, and ADA compliance
#Convert entry variable from character (YES vs NO) to logical variable

NYC_transit_data = read_csv(file = "./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>%
  janitor::clean_names() %>%
  select(line, station_name, station_latitude, station_longitude, starts_with("route"), entry, vending, entrance_type, ada) %>%
  mutate(entry = recode(entry, 'YES' = "TRUE", 'NO' = "FALSE"))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_integer(),
    ##   Route9 = col_integer(),
    ##   Route10 = col_integer(),
    ##   Route11 = col_integer(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

Write a short paragraph about this dataset - explain briefly what
variables the dataset contains, describe your data cleaning steps so
far, and give the dimension (rows x columns) of the resulting dataset.
Are these data tidy?

This dataset includes variables on line, station name, station latitude
and longitude, routes, entry, vending, entrance type, and ADA
compliance. My data cleaning steps have included loading the data and
cleaning the variable names, so they are all in snake case. Next, I
selected only the variables that I needed, discarding the rest. Lastly,
I converted the entry variable from a character to a logical variable.

The dimensions of the resulting dataset are 1868, 19

These data are not tidy because the the routes are spread across
multiple columns, with many missing values.

### Answer the following questions

-----

  - How many distinct stations are there? Note that stations are
    identified both by name and by line (e.g. 125th St A/B/C/D; 125st 1;
    125st 4/5)

  - How many stations are ADA compliant?

  - What proportion of station entrances / exits without vending allow
    entrance?

<!-- end list -->

``` r
#distinct removes duplicated rows based on line and station name
count(distinct(NYC_transit_data, line, station_name))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   465

``` r
#There are 465 distinct stations.

#count how many distinct stations are ADA compliant
NYC_transit_data %>%
  filter(ada == "TRUE") %>%
  count(station_name, line, ada) %>%
  summarise(n = n())
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    84

``` r
#82 distinct stations are ADA compliant

#proportion of station entrance/exit without vending allow entrance
NYC_vending = filter(NYC_transit_data, vending == "NO")
mean(NYC_vending$entry == TRUE)
```

    ## [1] 0.3770492

``` r
#Proportion is 0.377
```

### Reformat data

Reformat data so that route number and route name are distinct
variables. How many distinct stations serve the A train? Of the stations
that serve the A train, how many are ADA compliant?

``` r
#For all routes, separate route number and name into distinct variables
reform_NYC_transit = gather(NYC_transit_data, key = route_number, value = route_name, route1:route11)

#How many distinct stations serve the A train?
filter_NYC_transit_A = filter(reform_NYC_transit, route_name == 'A')
count(distinct(filter_NYC_transit_A, line, station_name))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    60

``` r
#60 

#of stations that serve A train, how many are ADA compliant?
filter_NYC_transit_A %>%
  filter(ada == "TRUE") %>%
  count(station_name, line, ada) %>%
  summarise(n = n())
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    17

``` r
#Out of distinct stations that serve A train, 17 are ADA compliant
```

## Problem 2

``` r
#specify the sheet in the Excel file and to omit columns containing notes (using the range argument and cell_cols() function)
trash_wheel_data = read_excel("./data/HealthyHarborWaterWheelTotals2017-9-26.xlsx", range = cell_cols(1:14)) %>%
  janitor::clean_names()
```

## Problem 3

``` r
#devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)

data(brfss_smart2010)

brfss_smart2010
```

    ## # A tibble: 134,203 x 23
    ##     Year Locationabbr Locationdesc Class Topic Question Response
    ##    <int> <chr>        <chr>        <chr> <chr> <chr>    <chr>   
    ##  1  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Excelle~
    ##  2  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Very go~
    ##  3  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Good    
    ##  4  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Fair    
    ##  5  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Poor    
    ##  6  2010 AL           AL - Jeffer~ Heal~ Fair~ Health ~ Good or~
    ##  7  2010 AL           AL - Jeffer~ Heal~ Fair~ Health ~ Fair or~
    ##  8  2010 AL           AL - Jeffer~ Heal~ Heal~ Do you ~ Yes     
    ##  9  2010 AL           AL - Jeffer~ Heal~ Heal~ Do you ~ No      
    ## 10  2010 AL           AL - Jeffer~ Heal~ Unde~ Adults ~ Yes     
    ## # ... with 134,193 more rows, and 16 more variables: Sample_Size <int>,
    ## #   Data_value <dbl>, Confidence_limit_Low <dbl>,
    ## #   Confidence_limit_High <dbl>, Display_order <int>,
    ## #   Data_value_unit <chr>, Data_value_type <chr>,
    ## #   Data_Value_Footnote_Symbol <chr>, Data_Value_Footnote <chr>,
    ## #   DataSource <chr>, ClassId <chr>, TopicId <chr>, LocationID <chr>,
    ## #   QuestionID <chr>, RESPID <chr>, GeoLocation <chr>

``` r
janitor::clean_names(brfss_smart2010)
```

    ## # A tibble: 134,203 x 23
    ##     year locationabbr locationdesc class topic question response
    ##    <int> <chr>        <chr>        <chr> <chr> <chr>    <chr>   
    ##  1  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Excelle~
    ##  2  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Very go~
    ##  3  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Good    
    ##  4  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Fair    
    ##  5  2010 AL           AL - Jeffer~ Heal~ Over~ How is ~ Poor    
    ##  6  2010 AL           AL - Jeffer~ Heal~ Fair~ Health ~ Good or~
    ##  7  2010 AL           AL - Jeffer~ Heal~ Fair~ Health ~ Fair or~
    ##  8  2010 AL           AL - Jeffer~ Heal~ Heal~ Do you ~ Yes     
    ##  9  2010 AL           AL - Jeffer~ Heal~ Heal~ Do you ~ No      
    ## 10  2010 AL           AL - Jeffer~ Heal~ Unde~ Adults ~ Yes     
    ## # ... with 134,193 more rows, and 16 more variables: sample_size <int>,
    ## #   data_value <dbl>, confidence_limit_low <dbl>,
    ## #   confidence_limit_high <dbl>, display_order <int>,
    ## #   data_value_unit <chr>, data_value_type <chr>,
    ## #   data_value_footnote_symbol <chr>, data_value_footnote <chr>,
    ## #   data_source <chr>, class_id <chr>, topic_id <chr>, location_id <chr>,
    ## #   question_id <chr>, respid <chr>, geo_location <chr>

``` r
#focus on the “Overall Health” topic
#exclude variables for class, topic, question, sample size, and everything from lower confidence limit to GeoLocation

clean_brfss = filter(brfss_smart2010, Topic == "Overall Health") %>%
  select(Year, Locationabbr, Locationdesc, Response, Data_value) 


#select(brfss_smart2010, -Class, -Topic, -Question, -Sample_Size, -Confidence_limit_Low:GeoLocation)

#structure data so that responses (excellent to poor) are variables taking the value of Data_value

clean_brfss$Response = clean_brfss$Data_value

#create a new variable showing the proportion of responses that were “Excellent” or “Very Good”
clean_brfss$exc_good_proportion = mean(clean_brfss$Response == "Excellent" & clean_brfss$Response == "Very Good")
```
